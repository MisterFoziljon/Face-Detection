{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a19a42-f98d-4d65-9f85-4f27f006131a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "import torch\n",
    "from ultralytics import YOLO\n",
    "\n",
    "from RT.models.common import PostDetect, optim\n",
    "\n",
    "try:\n",
    "    import onnxsim\n",
    "except ImportError:\n",
    "    onnxsim = None\n",
    "\n",
    "from io import BytesIO\n",
    "\n",
    "PostDetect.conf_thres = 0.25\n",
    "PostDetect.iou_thres = 0.65\n",
    "PostDetect.topk = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df998df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"best.pt\"\n",
    "input_shape = (1,3,640,640)\n",
    "\n",
    "b = input_shape[0]\n",
    "\n",
    "Yolo_model = YOLO(model_name)\n",
    "model = Yolo_model.model.fuse().eval()\n",
    "\n",
    "device = \"cuda:0\"\n",
    "\n",
    "for m in model.modules():\n",
    "    optim(m)\n",
    "    m.to(device)\n",
    "    \n",
    "model.to(device)\n",
    "\n",
    "fake_input = torch.randn(input_shape).to(device)\n",
    "for _ in range(2):\n",
    "    model(fake_input)\n",
    "\n",
    "save_path = model_name.replace('.pt', '.onnx')\n",
    "\n",
    "with BytesIO() as f:\n",
    "    torch.onnx.export(\n",
    "        model,\n",
    "        fake_input,\n",
    "        f,\n",
    "        opset_version=11,\n",
    "        input_names=['images'],\n",
    "        output_names=['num_dets', 'bboxes', 'scores', 'labels'])\n",
    "    f.seek(0)\n",
    "    onnx_model = onnx.load(f)\n",
    "onnx.checker.check_model(onnx_model)\n",
    "\n",
    "shapes = [b, 1, b, 100 , 4, b, 100 , b, 100]\n",
    "\n",
    "for i in onnx_model.graph.output:\n",
    "    for j in i.type.tensor_type.shape.dim:\n",
    "        j.dim_param = str(shapes.pop(0))\n",
    "#if args.sim:\n",
    "try:\n",
    "    onnx_model, check = onnxsim.simplify(onnx_model)\n",
    "    assert check, 'assert check failed'\n",
    "\n",
    "except Exception as e:\n",
    "    print(f'Simplifier failure: {e}')\n",
    "\n",
    "onnx.save(onnx_model, save_path)\n",
    "print(f'ONNX export success, saved as {save_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc4cae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from RT.models.utils import blob\n",
    "from RT.models.torch_utils import det_postprocess\n",
    "from RT.models.cudart_api import TRTEngine\n",
    "from RT.models import EngineBuilder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e6840e-25ee-4017-bd34-174d6cedf30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "builder = EngineBuilder(\"best.onnx\", device)\n",
    "builder.seg = True\n",
    "builder.build(fp16=True, \n",
    "              input_shape=list(input_shape),\n",
    "              iou_thres=0.65,\n",
    "              conf_thres=0.25,\n",
    "              topk=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb3e0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ImageBox(image, new_shape=(640, 640), color=(0, 0, 0)):\n",
    "    \n",
    "    width, height, channel = image.shape\n",
    "    \n",
    "    ratio = min(new_shape[0] / width, new_shape[1] / height)\n",
    "    \n",
    "    new_unpad = int(round(height * ratio)), int(round(width * ratio))\n",
    "    \n",
    "    dw, dh = (new_shape[0] - new_unpad[0])/2, (new_shape[1] - new_unpad[1])/2\n",
    "\n",
    "    if (height, width) != new_unpad:\n",
    "        image = cv2.resize(image, new_unpad, interpolation=cv2.INTER_LINEAR)\n",
    "    \n",
    "    top, bottom = int(round(dh - 0.1)), int(round(dh + 0.1))\n",
    "    left, right = int(round(dw - 0.1)), int(round(dw + 0.1))\n",
    "    \n",
    "    image = cv2.copyMakeBorder(image, top, bottom, left, right, cv2.BORDER_CONSTANT, value=color)\n",
    "    \n",
    "    return image, ratio, (dw, dh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbac9c22-2f29-4830-a0ea-7b8d54c6a398",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "enggine = TRTEngine('best.engine')\n",
    "H, W = enggine.inp_info[0].shape[-2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14eecb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rasmni sinovdan o'tkazish uchun\n",
    "\n",
    "frame = cv2.imread(\"image.jpg\")\n",
    "image, ratio, dwdh = ImageBox(frame)\n",
    "\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "tensor = blob(image, return_seg=False)\n",
    "tensor = torch.asarray(tensor)\n",
    "\n",
    "dwdh = np.array(dwdh * 2, dtype=np.float32)\n",
    "\n",
    "results = enggine(tensor)\n",
    "\n",
    "bboxes, scores, labels = det_postprocess(results)\n",
    "bboxes = (bboxes-dwdh)/ratio\n",
    "\n",
    "for (bbox, score, label) in zip(bboxes, scores, labels):\n",
    "    bbox = bbox.round().astype(np.int32).tolist()\n",
    "    cv2.rectangle(frame, (bbox[0],bbox[1]) , (bbox[2],bbox[3]) , (255,255,255), 1)\n",
    "\n",
    "cv2.imshow(\"input\", frame)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594a9a9f-8915-4e8c-81f2-a33af300ec56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Videoni sinovdan o'tkazish uchun\n",
    "\n",
    "video = cv2.VideoCapture(0)\n",
    "\n",
    "width = int(video.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "while True:\n",
    "    \n",
    "    ret, frame = video.read()\n",
    "    \n",
    "    image, ratio, dwdh = ImageBox(frame)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "    tensor = blob(image, return_seg=False)\n",
    "    tensor = torch.asarray(tensor)\n",
    "    \n",
    "    results = enggine(tensor)\n",
    "\n",
    "    dwdh = np.array(dwdh * 2, dtype=np.float32)\n",
    "    \n",
    "    bboxes, scores, labels = det_postprocess(results)\n",
    "    bboxes = (bboxes-dwdh)/ratio\n",
    "    \n",
    "    for (bbox, score, label) in zip(bboxes, scores, labels):\n",
    "        bbox = bbox.round().astype(np.int32).tolist()\n",
    "        cv2.rectangle(frame, (bbox[0],bbox[1]) , (bbox[2],bbox[3]) , (255,255,255), 1)\n",
    "\n",
    "    cv2.imshow(\"input\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "        \n",
    "video.release()\n",
    "cv2.destroyAllWindows()     "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
